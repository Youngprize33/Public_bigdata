{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 여러 페이지에서 크롤링을 위해 Session 사용\n",
    "    session = requests.Session()  \n",
    "    # scrape_list_page() 함수를 호출해서 제너레이터를 추출\n",
    "    response = session.get('http://www.hanbit.co.kr/store/books/new_book_list.html')\n",
    "    urls = scrape_list_page(response)\n",
    "    for url in urls:\n",
    "        response = session.get(url)  # Session을 사용해 상세 페이지를 추출\n",
    "        ebook = scrape_detail_page(response)  # 상세 페이지에서 상세 정보를 추출\n",
    "        print(ebook)  # 상세 정보 출력\n",
    "        break  #하나의 목록으로 테스트 해보기 (break를 주석처리하면 전체를 가져오게 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_list_page(response):\n",
    "    root = lxml.html.fromstring(response.content)\n",
    "    root.make_links_absolute(response.url)\n",
    "    for a in root.cssselect('.view_box .book_tit a'):\n",
    "        url = a.get('href')\n",
    "        yield url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_detail_page(response):\n",
    "    \"\"\"\n",
    "    상세 페이지의 Response에서 책 정보를 dict로 추출\n",
    "    \"\"\"\n",
    "    root = lxml.html.fromstring(response.content)\n",
    "    ebook = {\n",
    "        'url': response.url,\n",
    "        'title': root.cssselect('.store_product_info_box h3')[0].text_content(),\n",
    "        'price': root.cssselect('.pbr strong')[0].text_content(),\n",
    "        'content': [normalize_spaces(p.text_content())\n",
    "            for p in root.cssselect('#tabs_3 .hanbit_edit_view p')\n",
    "            if normalize_spaces(p.text_content()) != '']\n",
    "    }\n",
    "    return ebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spaces(s):\n",
    "    \"\"\"\n",
    "    연결된 공백을 하나의 공백으로 변경\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', s).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://www.hanbit.co.kr/store/books/look.php?p_code=B9143267027', 'title': '청소년 인문학 수업 - 1권', 'price': '16,650', 'content': ['프롤로그│학문과 삶의 접점을 이야기하는 인문학', '1강 르네상스 미술의 한 장면│이화진', '왜 알아야 할까', '1교시 ｜ 피렌체의 상인들', '2교시 ｜ 하늘을 향한 둥근 지붕', '3교시 ｜ 다윗은 어떻게 조각되었나', '4교시 ｜ 열린 창으로 바라본 세계', '5교시 ｜ 바티칸의 영광, 교황들의 찬가', '2강 천문이 곧 인문이다│안나미', '왜 알아야 할까', '1교시 ｜ 별이 알려주는 내 운명, 점성술', '2교시 ｜ 동양의 하늘 vs. 서양의 하늘', '3교시 ｜ 불길한 별의 꼬리, 혜성', '4교시 ｜ 태양 기록의 비과학과 과학', '5교시 ｜ 죽어야 다시 태어나는 별, 초신성', '3강 지도를 가진 자, 세계를 제패하다│이정선', '왜 알아야 할까', '1교시 ｜ 고지도의 매력과 유혹', '2교시 ｜ 한눈에 보는 세계지도의 역사', '3교시 ｜ 탐험의 시작, 미지의 세계를 향하다', '4교시 ｜ 지도상 바다 명칭의 유래와 우리 바다 ‘동해’', '5교시 ｜ <대동여지도>, 조선의 네트워크를 구축하다', '4강 나를 찾아가는 글쓰기│최옥정', '왜 알아야 할까', '1교시 ｜ 말과 글이 삶을 바꾼다', '2교시 ｜ 독서, 글쓰기에 연료를 공급하는 일', '3교시 ｜ 소설가의 독서법', '4교시 ｜ 어쨌든 문장이다', '5교시 ｜ 마음을 다잡는 글쓰기의 기술', '5강 클래식, 문학을 만나다│나성인', '왜 알아야 할까', '1교시 ｜ 작곡가의 상상 속에 녹아든 괴테의 문학 : <파우스트>', '2교시 ｜ 셰익스피어의 언어, 음악이 되다 : <한여름 밤의 꿈>', '3교시 ｜ 자유를 갈망하는 시대정신의 증언자, 빅토르 위고 : <리골레토>', '4교시 ｜ 신화의 해석, 혁명의 서막 : 오르페우스와 프로메테우스', '5교시 ｜ 바이블 인 뮤직 : 루터와 바흐의 수난곡', '6강 문장의 재발견│김나정', '왜 알아야 할까', '1교시 ｜ 벌레가 되고서야 벌레였음을 알다 : 프란츠 카프카 《변신》', '2교시 ｜ 마음도 해부가 되나요? : 나쓰메 소세키 《마음》', '3교시 ｜ 겨울 나무에서 봄 나무로 : 박완서 《나목》', '4교시 ｜ 사진사의 실수, 떠버리의 누설 : 발자크 《고리오 영감》', '5교시 ｜ 일생토록 사춘기 : 헤르만 헤세 《데미안》', '7강 천 년을 내다보는 혜안│민혜련', '왜 알아야 할까', '1교시 ｜ 암흑의 시대를 뚫고 피어난 르네상스의 빛', '2교시 ｜ 프랑스, 르네상스의 열매를 따다', '3교시 ｜ 계몽주의와 프랑스대혁명', '4교시 ｜ 신은 떠났다, 과학혁명의 도달점, 산업혁명', '5교시 ｜ 문화의 카오스, 아무도 답을 주지 않는다', '8강 조선의 대중문화│안나미', '왜 알아야 할까', '1교시 ｜ 임진왜란, 한류의 시작', '2교시 ｜ 조선시대 인어 이야기 : 유몽인의 《어우야담》', '3교시 ｜ 조선의 백과사전 : 이수광의 《지봉유설》', '4교시 ｜ 조선 최고의 식객 : 허균의 《도문대작》', '5교시 ｜ 선비, 꽃을 즐기다', '9강 스크린으로 부활한 천재들│최은', '왜 알아야 할까', '1교시 ｜ ‘작업’의 신 피카소', '2교시 ｜ 고흐가 남쪽으로 간 까닭은?', '3교시 ｜ 전쟁 중에 예술을 한다는 것 : 르누아르', '4교시 ｜ 세기말, 분열된 정신을 장식한 화가 : 클림트', '5교시 ｜ 제자, 연인 그리고 조각가 : 까미유 끌로델', '10강 인간의 삶과 미래 기술│이종관', '왜 알아야 할까', '1교시 ｜ 인공지능 그리고 윤동주', '2교시 ｜ 질문하는 인간의 내일', '3교시 ｜ 도구의 존재론과 애플의 혁신', '4교시 ｜ 일자리의 미래와 또 다른 위험', '5교시 ｜ 독일의 번영과 문화적 인간', '참고문헌', '출처', '저자 소개']}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 여러 페이지에서 크롤링을 위해 Session 사용\n",
    "    session = requests.Session()  \n",
    "    # scrape_list_page() 함수를 호출해서 제너레이터를 추출\n",
    "    response = session.get('http://www.hanbit.co.kr/store/books/new_book_list.html')\n",
    "    urls = scrape_list_page(response)\n",
    "    for url in urls:\n",
    "        response = session.get(url)  # Session을 사용해 상세 페이지를 추출\n",
    "        ebook = scrape_detail_page(response)  # 상세 페이지에서 상세 정보를 추출\n",
    "        print(ebook)  # 상세 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_list_page(response):\n",
    "    root = lxml.html.fromstring(response.content)\n",
    "    root.make_links_absolute(response.url)\n",
    "    for a in root.cssselect('.view_box .book_tit a'):\n",
    "        url = a.get('href')\n",
    "        yield url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_detail_page(response):\n",
    "    \"\"\"\n",
    "    상세 페이지의 Response에서 책 정보를 dict로 추출\n",
    "    \"\"\"\n",
    "    root = lxml.html.fromstring(response.content)\n",
    "    ebook = {\n",
    "        'title': root.cssselect('.store_product_info_box h3')[0].text_content(),\n",
    "    }\n",
    "    return ebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spaces(s):\n",
    "    \"\"\"\n",
    "    연결된 공백을 하나의 공백으로 변경\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', s).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '청소년 인문학 수업 - 1권'}\n",
      "{'title': '청소년 인문학 수업 - 2권'}\n",
      "{'title': '처음 시작하는 파이썬(2판)'}\n",
      "{'title': '게임 오버'}\n",
      "{'title': '처음 시작하는 딥러닝'}\n",
      "{'title': '초소형 머신러닝 TinyML'}\n",
      "{'title': '퀀트 전략을 위한 인공지능 트레이딩'}\n",
      "{'title': '회사에서 바로 통하는 실무 엑셀 매크로&VBA'}\n",
      "{'title': '오늘도 뇌는 거짓말을 한다'}\n",
      "{'title': '허팝만 따라 해봐! 유튜브 정석'}\n",
      "{'title': '딥러닝을 위한 선형대수학'}\n",
      "{'title': '이것이 취업을 위한 코딩 테스트다 with 파이썬'}\n",
      "{'title': '유닉스의 탄생'}\n",
      "{'title': '회사에서 바로 통하는  오토캐드 AutoCAD 2021'}\n",
      "{'title': 'IT CookBook, 오라클로 배우는 데이터베이스 개론과 실습(2판)'}\n",
      "{'title': '별, 걔 다 그립네'}\n",
      "{'title': '대학을 버려야 대학이 산다'}\n",
      "{'title': 'IT CookBook, 따라 하면서 배우는 사물인터넷'}\n",
      "{'title': '우리 아이 처음 놀이'}\n",
      "{'title': '재미있고 빠른 첫 한글 4권 쌍자음∙받침'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
